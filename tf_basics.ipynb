{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tf_basics.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOPEpT/lAjpGPEFLw6LnE4P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RitulMohan/TF.Autoencoder/blob/main/tf_basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Rf5De39q3UhP"
      },
      "outputs": [],
      "source": [
        "#importing all the neeeded libraraies\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import layers, losses\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# tf.keras.layers.Dense\n",
        "\n",
        "Just your regular densely-connected NN layer.\n",
        "\n",
        "Dense implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use_bias is True). These are all attributes of Dense.\n",
        "\n",
        "\n",
        "Besides, layer attributes cannot be modified after the layer has been called once (except the trainable attribute). When a popular kwarg input_shape is passed, then keras will create an input layer to insert before the current layer. This can be treated equivalent to explicitly defining an InputLayer"
      ],
      "metadata": {
        "id": "U6LmPgGj3qcA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.layers.Dense(\n",
        "    units,\n",
        "    activation=None,\n",
        "    use_bias=True,\n",
        "    kernel_initializer='glorot_uniform',\n",
        "    bias_initializer='zeros',\n",
        "    kernel_regularizer=None,\n",
        "    bias_regularizer=None,\n",
        "    activity_regularizer=None,\n",
        "    kernel_constraint=None,\n",
        "    bias_constraint=None,\n",
        "    **kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "oyNYxG1d3l1B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input shape:\n",
        "\n",
        "N-D tensor with shape: (batch_size, ..., input_dim). The most common situation would be a 2D input with shape (batch_size, input_dim)\n",
        "\n",
        "Output shape:\n",
        "\n",
        "N-D tensor with shape: (batch_size, ..., units). For instance, for a 2D input with shape (batch_size, input_dim), the output would have shape (batch_size, units)."
      ],
      "metadata": {
        "id": "THbhTBuX6HHU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a `Sequential` model and add a Dense layer as the first layer.\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.Input(shape=(16,)))\n",
        "model.add(tf.keras.layers.Dense(32, activation='relu'))\n",
        "# Now the model will take as input arrays of shape (None, 16)\n",
        "# and output arrays of shape (None, 32).\n",
        "# Note that after the first layer, you don't need to specify\n",
        "# the size of the input anymore:\n",
        "model.add(tf.keras.layers.Dense(32))\n",
        "model.output_shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BszvRxAD4gCu",
        "outputId": "d3db8d92-46d7-479b-abb7-7590cebeb654"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "batch_size:\n",
        "\n",
        "Integer or None. Number of samples per batch of computation. If unspecified, batch_size will default to 32. Do not specify the batch_size if your data is in the form of a dataset, generators, or keras.utils.Sequence instances (since they generate batches).\n",
        "\n",
        "\n",
        "epochs:\n",
        " \n",
        "Integer. Number of epochs to train the model. An epoch is an iteration over the entire x and y data provided (unless the steps_per_epoch flag is set to something other than None). Note that in conjunction with initial_epoch, epochs is to be understood as \"final epoch\". The model is not trained for a number of iterations given by epochs, but merely until the epoch of index epochs is reached."
      ],
      "metadata": {
        "id": "NJvqBUAR8hCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cEwmg6qf8pO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}